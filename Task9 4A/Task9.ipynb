{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b96a6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: gradio in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.23.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.8.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (1.8.0)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (3.10.16)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (11.0.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.11.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.11.4)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.46.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.15.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (2.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch gradio datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5798ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (0.30.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from evaluate) (24.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.11.16)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29093e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      " the transformers library provides state-of-the-art models for various NLP tasks. developers can quickly integrate advanced NLP capabilities into their applications. the community-driven approach ensures continuous improvement and innovation in the library.\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import gradio as gr\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# --- Load model and tokenizer ---\n",
    "model_name = 't5-small'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# --- Define summarization function ---\n",
    "def summarize(text):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# --- Example test ---\n",
    "text = \"\"\" The Hugging Face library has revolutionized the field of natural language processing with its transformers library.\n",
    "This library provides state-of-the-art models for various NLP tasks including text summarization, text classification, question answering, and more. \n",
    "With easy-to-use APIs and pre-trained models, developers can quickly integrate advanced NLP capabilities into their applications. \n",
    "The community-driven approach ensures continuous improvement and innovation in the library, making it a valuable resource for both researchers and practitioners.\"\"\"\n",
    "\n",
    "print(\"Summary:\\n\", summarize(text))\n",
    "\n",
    "# --- Gradio Interface ---\n",
    "# Gradio interface\n",
    "iface = gr.Interface(fn=summarize, inputs=\"text\", outputs=\"text\", title=\"Text Summarization with T5\", description=\"Enter text to get a summarized version using the T5 model.\")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e233f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting breadability>=0.1.20 (from sumy)\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sumy) (2.32.3)\n",
      "Collecting pycountry>=18.2.23 (from sumy)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sumy) (3.9.1)\n",
      "Requirement already satisfied: chardet in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from breadability>=0.1.20->sumy) (3.0.4)\n",
      "Requirement already satisfied: lxml>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from breadability>=0.1.20->sumy) (5.3.1)\n",
      "Requirement already satisfied: click in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.0.2->sumy) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.7.0->sumy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.7.0->sumy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.7.0->sumy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.7.0->sumy) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.6)\n",
      "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/6.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.1/6.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.0/6.3 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.3 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 1.7 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: breadability, docopt\n",
      "  Building wheel for breadability (setup.py): started\n",
      "  Building wheel for breadability (setup.py): finished with status 'done'\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21740 sha256=35926108dd4117b7a8febd71d7113dc1488f6ffd692a840747fe7fbbf86b116b\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\32\\99\\64\\59305409cacd03aa03e7bddf31a9db34b1fa7033bd41972662\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13774 sha256=cb161f38b191444049551eecfd649533b392d28e296d7bed4389db7eb1aab89a\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\1a\\bf\\a1\\4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "Successfully built breadability docopt\n",
      "Installing collected packages: docopt, pycountry, breadability, sumy\n",
      "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-24.6.1 sumy-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ff17aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt', download_dir='nltk_data')\n",
    "nltk.data.path.append('./nltk_data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "350b00c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6ea243d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello', 'this', 'is', 'GeeksForGeeks')\n",
      "('We', 'are', 'a', 'computer', 'science', 'portal', 'for', 'geeks', 'offering', 'a', 'wide', 'range', 'of', 'articles', 'tutorials', 'and', 'resources', 'on', 'various', 'topics', 'in', 'computer', 'science', 'and', 'programming')\n",
      "('Our', 'mission', 'is', 'to', 'provide', 'quality', 'education', 'and', 'knowledge', 'sharing', 'to', 'help', 'you', 'excel', 'in', 'your', 'career', 'and', 'academic', 'pursuits')\n",
      "('Whether', 'you', 'a', 'beginner', 'looking', 'to', 'learn', 'the', 'basics', 'of', 'coding', 'or', 'an', 'experienced', 'developer', 'seeking', 'advanced', 'concepts', 'GeeksForGeeks', 'has', 'something', 'for', 'everyone')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "import nltk\n",
    "\n",
    "# Download punkt tokenizer if not already present\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = Tokenizer(\"en\")\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"Hello, this is GeeksForGeeks! We are a computer science portal for geeks, offering a wide range of articles, tutorials, and resources on various topics in computer science and programming. Our mission is to provide quality education and knowledge sharing to help you excel in your career and academic pursuits. Whether you're a beginner looking to learn the basics of coding or an experienced developer seeking advanced concepts, GeeksForGeeks has something for everyone.\"\"\"\n",
    "\n",
    "# Tokenize text into sentences\n",
    "sentences = tokenizer.to_sentences(text)\n",
    "\n",
    "# Tokenize sentences into words and print them\n",
    "for sentence in sentences:\n",
    "    print(tokenizer.to_words(sentence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8904db71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blog\n"
     ]
    }
   ],
   "source": [
    "from sumy.nlp.stemmers import Stemmer\n",
    "stemmer = Stemmer(\"en\")\n",
    "stem = stemmer(\"Blogging\") \n",
    "print(stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c82c9ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.\n",
      "Colloquially, the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def summarize_paragraph(paragraph, sentences_count=2):\n",
    "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
    "\n",
    "    summarizer = LuhnSummarizer(Stemmer(\"english\"))\n",
    "    summarizer.stop_words = get_stop_words(\"english\")\n",
    "\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    paragraph = \"\"\"Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast \n",
    "                   to the natural intelligence displayed by humans and animals. Leading AI textbooks define \n",
    "                   the field as the study of \"intelligent agents\": any device that perceives its environment \n",
    "                   and takes actions that maximize its chance of successfully achieving its goals. Colloquially, \n",
    "                   the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \n",
    "                   \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\"\"\"\n",
    "\n",
    "    sentences_count = 2\n",
    "    summary = summarize_paragraph(paragraph, sentences_count)\n",
    "\n",
    "    for sentence in summary:\n",
    "        print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "352650f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.\n",
      "Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def summarize_paragraph(paragraph, sentences_count=2, bonus_words=None, stigma_words=None, null_words=None):\n",
    "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
    "\n",
    "    summarizer = EdmundsonSummarizer(Stemmer(\"english\"))\n",
    "    summarizer.stop_words = get_stop_words(\"english\")\n",
    "\n",
    "    if bonus_words:\n",
    "        summarizer.bonus_words = bonus_words\n",
    "    if stigma_words:\n",
    "        summarizer.stigma_words = stigma_words\n",
    "    if null_words:\n",
    "        summarizer.null_words = null_words\n",
    "\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    paragraph = \"\"\"Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast \n",
    "                   to the natural intelligence displayed by humans and animals. Leading AI textbooks define \n",
    "                   the field as the study of \"intelligent agents\": any device that perceives its environment \n",
    "                   and takes actions that maximize its chance of successfully achieving its goals. Colloquially, \n",
    "                   the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \n",
    "                   \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\"\"\"\n",
    "\n",
    "    sentences_count = 2\n",
    "    bonus_words = [\"intelligence\", \"AI\"]\n",
    "    stigma_words = [\"contrast\"]\n",
    "    null_words = [\"the\", \"of\", \"and\", \"to\", \"in\"]\n",
    "\n",
    "    summary = summarize_paragraph(paragraph, sentences_count, bonus_words, stigma_words, null_words)\n",
    "\n",
    "    for sentence in summary:\n",
    "        print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3a5322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\n",
      "Colloquially, the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def summarize_paragraph(paragraph, sentences_count=2):\n",
    "    parser = PlaintextParser.from_string(paragraph, Tokenizer(\"english\"))\n",
    "\n",
    "    summarizer = LsaSummarizer(Stemmer(\"english\"))\n",
    "    summarizer.stop_words = get_stop_words(\"english\")\n",
    "\n",
    "    summary = summarizer(parser.document, sentences_count)\n",
    "    return summary\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    paragraph = \"\"\"Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast \n",
    "                   to the natural intelligence displayed by humans and animals. Leading AI textbooks define \n",
    "                   the field as the study of \"intelligent agents\": any device that perceives its environment \n",
    "                   and takes actions that maximize its chance of successfully achieving its goals. Colloquially, \n",
    "                   the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \n",
    "                   \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\"\"\"\n",
    "\n",
    "    sentences_count = 2\n",
    "    summary = summarize_paragraph(paragraph, sentences_count)\n",
    "\n",
    "    for sentence in summary:\n",
    "        print(sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
